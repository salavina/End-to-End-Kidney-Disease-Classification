{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/milad/projects/End-to-End-Kidney-Disease-Classification/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/milad/projects/End-to-End-Kidney-Disease-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "MLFLOW_TRACKING_URI = os.environ[\"MLFLOW_TRACKING_URI\"]\n",
    "MLFLOW_TRACKING_USERNAME = os.environ[\"MLFLOW_TRACKING_USERNAME\"]\n",
    "MLFLOW_TRACKING_PASSWORD = os.environ[\"MLFLOW_TRACKING_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('artifacts/training/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update entity\n",
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class EvaluationConfig:\n",
    "    path_of_model: Path\n",
    "    training_data: Path\n",
    "    all_params: dict\n",
    "    mlflow_uri: str\n",
    "    params_image_size: list\n",
    "    params_batch_size: int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "    \n",
    "    \n",
    "    def get_evaluation_config(self) -> EvaluationConfig:\n",
    "        eval_config = EvaluationConfig(\n",
    "            path_of_model = 'artifacts/training/model.pth',\n",
    "            training_data = 'artifacts/data_ingestion/kidney-ct-scan-image',\n",
    "            all_params = self.params,\n",
    "            mlflow_uri = MLFLOW_TRACKING_URI,\n",
    "            params_image_size = self.params.IMAGE_SIZE,\n",
    "            params_batch_size = self.params.BATCH_SIZE\n",
    "        )\n",
    "        \n",
    "        return eval_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update components\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "from urllib.parse import urlparse\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLazyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        if self.transform:\n",
    "            x = self.transform(self.dataset[index][0])\n",
    "        else:\n",
    "            x = self.dataset[index][0]\n",
    "        y = self.dataset[index][1]\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "\n",
    "class Evaluation:\n",
    "    def __init__(self, config: EvaluationConfig):\n",
    "        self.config = config\n",
    "        self.loss_fn = torch.nn.CrossEntropyLoss(reduction='mean')\n",
    "\n",
    "    def set_seed(self, seed=42):\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False    \n",
    "        torch.manual_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    def set_loaders(self):\n",
    "        # This method allows the user to define which train_loader (and val_loader, optionally) to use\n",
    "        # Both loaders are then assigned to attributes of the class\n",
    "        # So they can be referred to later\n",
    "        # Image transformations\n",
    "        image_transforms = {\n",
    "            # Train uses data augmentation\n",
    "            'train':\n",
    "            transforms.Compose([\n",
    "                transforms.RandomResizedCrop(size=200, scale=(0.8, 1.0)),\n",
    "                transforms.RandomRotation(degrees=30),\n",
    "                transforms.ColorJitter(),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.CenterCrop(size=64),  # Image net standards\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                    [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "            ]),\n",
    "            # Validation does not use augmentation\n",
    "            'val':\n",
    "            transforms.Compose([\n",
    "                transforms.Resize(size=64),\n",
    "                transforms.CenterCrop(size=180),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ])\n",
    "        }\n",
    "        self.dataset = ImageFolder(root=self.config.training_data)\n",
    "        train, val = torch.utils.data.random_split(self.dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(42))\n",
    "        traindataset = MyLazyDataset(train, transform=image_transforms['train'])\n",
    "        valdataset = MyLazyDataset(val, transform=image_transforms['val'])\n",
    "        trainLoader = DataLoader(traindataset , batch_size=self.config.params_batch_size, shuffle=True)\n",
    "        valLoader = DataLoader(valdataset, batch_size=self.config.params_batch_size)\n",
    "        \n",
    "        return trainLoader, valLoader\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def load_model(path: Path) -> torch.nn.Module:\n",
    "        checkpoint = torch.load(path)\n",
    "        model = models.vgg16(pretrained=True)\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "        model.classifier = checkpoint['classifier']\n",
    "        # Load in the state dict\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        model = model.to('cuda')\n",
    "        return model\n",
    "\n",
    "\n",
    "    def evaluation(self, val_on_gpu=True):\n",
    "        self.model = self.load_model(self.config.path_of_model)\n",
    "        _, valLoader = self.set_loaders()\n",
    "        # Test the model\n",
    "        self.model.eval()\n",
    "\n",
    "        val_loss = 0\n",
    "        val_acc = 0\n",
    "\n",
    "        for data, target in valLoader:\n",
    "            if val_on_gpu:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            pred = self.model(data)\n",
    "            \n",
    "            loss = self.loss_fn(pred, target)\n",
    "\n",
    "            val_loss += loss.item() * data.size(0)\n",
    "\n",
    "            \n",
    "            _, pred = torch.max(pred, dim=1)\n",
    "            correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "            accuracy = torch.mean(\n",
    "                correct_tensor.type(torch.FloatTensor))\n",
    "            # Multiply average accuracy times the number of examples\n",
    "            val_acc += accuracy.item() * data.size(0)\n",
    "\n",
    "        val_loss /= len(valLoader.dataset)\n",
    "        val_acc /= len(valLoader.dataset)\n",
    "        \n",
    "        self.score = (val_loss, val_acc)\n",
    "        \n",
    "        print(f'Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')\n",
    "        \n",
    "        self.save_score()\n",
    "\n",
    "    def save_score(self):\n",
    "        scores = {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "        save_json(path=Path(\"scores.json\"), data=scores)\n",
    "\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "        tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "        \n",
    "        with mlflow.start_run():\n",
    "            mlflow.log_params(self.config.all_params)\n",
    "            mlflow.log_metrics(\n",
    "                {\"loss\": self.score[0], \"accuracy\": self.score[1]}\n",
    "            )\n",
    "            # Model registry does not work with file store\n",
    "            if tracking_url_type_store != \"file\":\n",
    "\n",
    "                # Register the model\n",
    "                # There are other ways to use the Model Registry, which depends on the use case,\n",
    "                # please refer to the doc for more information:\n",
    "                # https://mlflow.org/docs/latest/model-registry.html#api-workflow\n",
    "                mlflow.pytorch.log_model(self.model, \"model\", registered_model_name=\"VGG16Model\")\n",
    "            else:\n",
    "                mlflow.pytorch.log_model(self.model, \"model\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-18 05:12:33,969: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-02-18 05:12:33,975: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-18 05:12:33,977: INFO: common: created directory at: artifacts]\n",
      "Loss: 1.9132, Accuracy: 0.5161\n",
      "[2024-02-18 05:12:36,596: INFO: common: json file saved at: scores.json]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/02/18 05:12:51 WARNING mlflow.utils.environment: Encountered an unexpected error while inferring pip requirements (model URI: /tmp/tmp5y1610v0/model/data, flavor: pytorch), fall back to return ['torch==2.0.1', 'cloudpickle==2.2.1']. Set logging level to DEBUG to see the full traceback.\n",
      "Registered model 'VGG16Model' already exists. Creating a new version of this model...\n",
      "2024/02/18 05:14:19 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: VGG16Model, version 3\n",
      "Created version '3' of model 'VGG16Model'.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    eval_config = config.get_evaluation_config()\n",
    "    evaluation = Evaluation(eval_config)\n",
    "    evaluation.evaluation()\n",
    "    evaluation.log_into_mlflow()\n",
    "\n",
    "except Exception as e:\n",
    "   raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
