{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/milad/projects/End-to-End-Kidney-Disease-Classification/research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/milad/projects/End-to-End-Kidney-Disease-Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareBaseModelConfig:\n",
    "    root_dir: Path\n",
    "    base_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    params_image_size: list\n",
    "    params_learning_rate: float\n",
    "    params_include_top: bool\n",
    "    params_weights: str\n",
    "    params_classes: int\n",
    "    params_pretrained: bool\n",
    "    params_batch_size: int\n",
    "    params_device: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self,\n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    \n",
    "\n",
    "    def get_prepare_base_model_config(self) -> PrepareBaseModelConfig:\n",
    "        config = self.config.prepare_base_model\n",
    "        \n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        prepare_base_model_config = PrepareBaseModelConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            base_model_path=Path(config.base_model_path),\n",
    "            updated_base_model_path=Path(config.updated_base_model_path),\n",
    "            params_image_size=self.params.IMAGE_SIZE,\n",
    "            params_learning_rate=self.params.LEARNING_RATE,\n",
    "            params_include_top=self.params.INCLUDE_TOP,\n",
    "            params_weights=self.params.WEIGHTS,\n",
    "            params_classes=self.params.CLASSES,\n",
    "            params_pretrained=self.params.PRETRAINED,\n",
    "            params_batch_size=self.params.BATCH_SIZE,\n",
    "            params_device=self.params.DEVICE\n",
    "        )\n",
    "\n",
    "        return prepare_base_model_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareBaseModel:\n",
    "    def __init__(self, config: PrepareBaseModelConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = models.vgg16(pretrained=self.config.params_pretrained)\n",
    "        self.model = self.model.to(self.config.params_device)\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "    @staticmethod\n",
    "    def _prepare_full_model(model, classes, freeze_all, freeze_till):\n",
    "        if freeze_all:\n",
    "            for param in model.parameters():\n",
    "                param.requires_grad = False\n",
    "        elif (freeze_till is not None) and (freeze_till > 0):\n",
    "            for param in model.parameters()[:-freeze_till]:\n",
    "                param.requires_grad = False\n",
    "\n",
    "        n_inputs = model.classifier[6].in_features\n",
    "        model.classifier[6] = nn.Sequential(\n",
    "        nn.Linear(n_inputs, 256), nn.ReLU(), nn.Dropout(0.4),\n",
    "        nn.Linear(256, classes), nn.LogSoftmax(dim=1))\n",
    "        # multi_loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
    "        return model\n",
    "    \n",
    "    \n",
    "    def update_base_model(self):\n",
    "        self.full_model = self._prepare_full_model(\n",
    "            model=self.model,\n",
    "            classes=self.config.params_classes,\n",
    "            freeze_all=True,\n",
    "            freeze_till=None\n",
    "        )\n",
    "        self.full_model = self.full_model.to(self.config.params_device)\n",
    "        # optimizer_top = torch.optim.Adam(self.full_model.parameters(), lr=self.config.params_learning_rate)\n",
    "        # checkpoint = {'model_state_dict': self.full_model.state_dict(),\n",
    "        #                 'optimizer_state_dict': optimizer_top.state_dict()}\n",
    "        summary(self.full_model, input_size=tuple(self.config.params_image_size), batch_size=self.config.params_batch_size, device=self.config.params_device)\n",
    "        self.save_model(checkpoint=self.full_model, path=self.config.updated_base_model_path)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def save_model(path: Path, checkpoint: dict):\n",
    "        torch.save(checkpoint, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-02-18 00:32:23,438: INFO: common: yaml file: config/config.yaml loaded successfully]\n",
      "[2024-02-18 00:32:23,441: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2024-02-18 00:32:23,443: INFO: common: created directory at: artifacts]\n",
      "[2024-02-18 00:32:23,444: INFO: common: created directory at: artifacts/prepare_base_model]\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [16, 64, 224, 224]           1,792\n",
      "              ReLU-2         [16, 64, 224, 224]               0\n",
      "            Conv2d-3         [16, 64, 224, 224]          36,928\n",
      "              ReLU-4         [16, 64, 224, 224]               0\n",
      "         MaxPool2d-5         [16, 64, 112, 112]               0\n",
      "            Conv2d-6        [16, 128, 112, 112]          73,856\n",
      "              ReLU-7        [16, 128, 112, 112]               0\n",
      "            Conv2d-8        [16, 128, 112, 112]         147,584\n",
      "              ReLU-9        [16, 128, 112, 112]               0\n",
      "        MaxPool2d-10          [16, 128, 56, 56]               0\n",
      "           Conv2d-11          [16, 256, 56, 56]         295,168\n",
      "             ReLU-12          [16, 256, 56, 56]               0\n",
      "           Conv2d-13          [16, 256, 56, 56]         590,080\n",
      "             ReLU-14          [16, 256, 56, 56]               0\n",
      "           Conv2d-15          [16, 256, 56, 56]         590,080\n",
      "             ReLU-16          [16, 256, 56, 56]               0\n",
      "        MaxPool2d-17          [16, 256, 28, 28]               0\n",
      "           Conv2d-18          [16, 512, 28, 28]       1,180,160\n",
      "             ReLU-19          [16, 512, 28, 28]               0\n",
      "           Conv2d-20          [16, 512, 28, 28]       2,359,808\n",
      "             ReLU-21          [16, 512, 28, 28]               0\n",
      "           Conv2d-22          [16, 512, 28, 28]       2,359,808\n",
      "             ReLU-23          [16, 512, 28, 28]               0\n",
      "        MaxPool2d-24          [16, 512, 14, 14]               0\n",
      "           Conv2d-25          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-26          [16, 512, 14, 14]               0\n",
      "           Conv2d-27          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-28          [16, 512, 14, 14]               0\n",
      "           Conv2d-29          [16, 512, 14, 14]       2,359,808\n",
      "             ReLU-30          [16, 512, 14, 14]               0\n",
      "        MaxPool2d-31            [16, 512, 7, 7]               0\n",
      "AdaptiveAvgPool2d-32            [16, 512, 7, 7]               0\n",
      "           Linear-33                 [16, 4096]     102,764,544\n",
      "             ReLU-34                 [16, 4096]               0\n",
      "          Dropout-35                 [16, 4096]               0\n",
      "           Linear-36                 [16, 4096]      16,781,312\n",
      "             ReLU-37                 [16, 4096]               0\n",
      "          Dropout-38                 [16, 4096]               0\n",
      "           Linear-39                  [16, 256]       1,048,832\n",
      "             ReLU-40                  [16, 256]               0\n",
      "          Dropout-41                  [16, 256]               0\n",
      "           Linear-42                    [16, 2]             514\n",
      "       LogSoftmax-43                    [16, 2]               0\n",
      "================================================================\n",
      "Total params: 135,309,890\n",
      "Trainable params: 1,049,346\n",
      "Non-trainable params: 134,260,544\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 9.19\n",
      "Forward/backward pass size (MB): 3500.47\n",
      "Params size (MB): 516.17\n",
      "Estimated Total Size (MB): 4025.82\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_base_model_config = config.get_prepare_base_model_config()\n",
    "    prepare_base_model = PrepareBaseModel(config=prepare_base_model_config)\n",
    "    prepare_base_model.get_base_model()\n",
    "    prepare_base_model.update_base_model()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kidney",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
